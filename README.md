# Book Scanner App ðŸ“š

A full-stack application that uses **Vision Language Models (VLMs)** to scan book images, identify titles via Google Books API, and provide AI-powered personalized reading recommendations.

**Version 1.2.0** - Now with VLM-based book recognition for 90-95% accuracy!

## Quick Links

- **ðŸ“– [Complete Documentation](project_specification.md)** - Full project specification and architecture
- **ðŸš€ [Quick Start Guide](QUICK_START.md)** - Setup instructions to get running fast
- **ðŸ’» [Development Guide](development.md)** - Local development setup

## What This App Does

1. **ðŸ“¸ Upload/Capture** - Take a photo of books on your shelf
2. **ðŸ¤– VLM Processing** - AI vision extracts book titles (90-95% accuracy!)
3. **ðŸ“š Book Lookup** - Finds books via Google Books API (with fuzzy matching)
4. **ðŸŽ¯ Smart Recommendations** - AI-powered suggestions based on your taste profile
5. **ðŸ“– Library Management** - Save and organize your book collection

## Technology Stack

### Backend (Complete âœ…)
- **FastAPI** - Modern Python web framework
- **PostgreSQL** - Database with SQLModel ORM
- **Vision LLMs** - Google Gemini/GPT-4o-mini/Claude Vision for book recognition
- **Google Books API** - Book metadata (free tier)
- **FuzzyWuzzy** - Intelligent matching for OCR errors

### Frontend (Complete âœ…)
- **React 19 + TypeScript** - Modern UI framework
- **Vite** - Fast build tool
- **Chakra UI** - Component library
- **TanStack Router + Query** - Type-safe routing and data fetching

## Quick Start

### 1. Get API Keys

You need at least ONE of these (Google Gemini recommended):

```bash
# Google Gemini (cheapest, best performance)
https://aistudio.google.com/app/apikey

# OR OpenAI (alternative)
https://platform.openai.com/api-keys

# OR Anthropic Claude (alternative)
https://console.anthropic.com/
```

### 2. Install Dependencies

```bash
# Backend
cd backend
pip install -e .

# Frontend
cd frontend
npm install
```

### 3. Configure Environment

Create `.env` in project root:

```env
# Database
POSTGRES_SERVER=localhost
POSTGRES_USER=postgres
POSTGRES_PASSWORD=changethis
POSTGRES_DB=book_scanner

# Security
SECRET_KEY=your-secret-key-here
FIRST_SUPERUSER=admin@example.com
FIRST_SUPERUSER_PASSWORD=changethis

# VLM Provider (add at least ONE)
GOOGLE_API_KEY=your-gemini-key-here
# OPENAI_API_KEY=your-openai-key-here
# ANTHROPIC_API_KEY=your-claude-key-here

# LLM Settings
LLM_ENABLED=true
LLM_PROVIDER=google  # google | openai | anthropic

# Frontend
FRONTEND_HOST=http://localhost:5173
```

### 4. Set Up Database

```bash
# Start PostgreSQL (via Docker)
docker-compose up -d postgres

# Run migrations
cd backend
alembic upgrade head

# Create admin user
python -m app.initial_data
```

### 5. Start Development Servers

```bash
# Backend (terminal 1)
cd backend
uvicorn app.main:app --reload

# Frontend (terminal 2)
cd frontend
npm run dev
```

**Backend**: http://localhost:8000
**Frontend**: http://localhost:5173
**API Docs**: http://localhost:8000/docs

## Project Structure

```
book-scanner/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/routes/
â”‚   â”‚   â”‚   â””â”€â”€ books.py                     # Book scanning endpoints
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ ocr_service.py               # VLM-based title extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ google_books_service.py      # Book metadata lookup
â”‚   â”‚   â”‚   â”œâ”€â”€ recommendation_service.py    # AI recommendations
â”‚   â”‚   â”‚   â””â”€â”€ llm/
â”‚   â”‚   â”‚       â”œâ”€â”€ providers/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ google.py            # Gemini Vision
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ openai.py            # GPT-4o-mini Vision
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ anthropic.py         # Claude Vision
â”‚   â”‚   â”‚       â””â”€â”€ factory.py               # Provider selection
â”‚   â”‚   â””â”€â”€ models.py                        # Book & UserLibrary models
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/                      # Book scanner UI (complete)
â”‚       â”‚   â”œâ”€â”€ Scanner/                     # Image upload & results
â”‚       â”‚   â”œâ”€â”€ Profile/                     # Library management
â”‚       â”‚   â””â”€â”€ Dashboard/                   # Home page
â”‚       â””â”€â”€ routes/                          # Page routing
â””â”€â”€ docker-compose.yml
```

## API Endpoints

All endpoints require authentication (JWT token).

### Book Scanning
- `POST /api/v1/books/scan` - Upload image, get detected books + recommendations
- `POST /api/v1/books/library/add/{google_books_id}` - Add book to library
- `GET /api/v1/books/library` - Get your library
- `DELETE /api/v1/books/library/remove/{book_id}` - Remove from library

### Authentication
- `POST /api/v1/login/access-token` - Login
- `POST /api/v1/users/signup` - Register

## Features

### âœ… Complete
**Backend:**
- âœ… VLM-based book title extraction (Google Gemini/GPT-4o/Claude Vision)
- âœ… 90-95% accuracy on book covers and spines
- âœ… Automatic rotation handling (vertical/horizontal text)
- âœ… Google Books API integration with fuzzy matching
- âœ… AI-powered recommendation engine
- âœ… User library (taste profile) management
- âœ… PostgreSQL database with SQLModel ORM
- âœ… JWT authentication & authorization
- âœ… Rate limiting (10 scans/min per IP)

**Frontend:**
- âœ… Book scanner page with camera/file upload
- âœ… Onboarding flow (min 5 books to start)
- âœ… Library management interface
- âœ… Dashboard with personalized recommendations
- âœ… User settings (profile, password, theme, delete account)
- âœ… Dark mode support
- âœ… Responsive mobile-first design

### ðŸŽ¯ VLM Accuracy vs Old Tesseract

| Feature | Tesseract (Old) | VLM (New) |
|---------|----------------|-----------|
| Accuracy | 60-70% | **90-95%** |
| Rotation handling | Manual logic | Automatic |
| Blur tolerance | Poor | Excellent |
| Speed | 2-3s | 1-3s |
| Code complexity | 600 lines | 230 lines |

## Deployment (Free Tier)

### Recommended Stack
- **Backend**: [Render.com](https://render.com) (free tier)
- **Frontend**: [Vercel](https://vercel.com) (free tier)
- **Database**: [Supabase](https://supabase.com) (free tier)

**Total Cost**: $0/month for personal use

See [BOOK_SCANNER_README.md](BOOK_SCANNER_README.md) for deployment instructions.

## How the Recommendation Engine Works

```python
# For each detected book, calculate match score:
score = (
    0.4 * author_match +      # Books by authors you've read
    0.3 * category_match +    # Books in genres you like
    0.2 * rating_score +      # Higher rated books
    0.1 * popularity_score    # Based on # of ratings
)
```

Books already in your library are filtered out. Recommendations are sorted by match score.

## Development

### Generate Frontend API Client
After backend changes, regenerate TypeScript types:

```bash
cd frontend
npm run generate-client
```

### Run Tests
```bash
cd backend
pytest
```

### Code Quality
```bash
cd backend
ruff check .
mypy .
```

## Environment Variables

Key variables in `.env`:

```env
# Database
POSTGRES_SERVER=localhost
POSTGRES_USER=postgres
POSTGRES_PASSWORD=changethis
POSTGRES_DB=book_scanner

# Security
SECRET_KEY=your-secret-key-here
FIRST_SUPERUSER=admin@example.com
FIRST_SUPERUSER_PASSWORD=changethis

# Frontend
FRONTEND_HOST=http://localhost:5173
```

## Troubleshooting

### "No LLM providers configured"
- **Cause**: Missing API key
- **Fix**: Add at least one API key to `.env`:
  ```env
  GOOGLE_API_KEY=your-key-here
  LLM_ENABLED=true
  ```
- **Get keys**:
  - [Google Gemini (cheapest)](https://aistudio.google.com/app/apikey)
  - [OpenAI](https://platform.openai.com/api-keys)
  - [Anthropic](https://console.anthropic.com/)

### Poor book detection accuracy
- **Tip 1**: Use well-lit, focused images
- **Tip 2**: Book titles should be clearly visible (not too blurry)
- **Tip 3**: Try horizontal or vertical orientation (VLM handles both)
- **VLM advantage**: Works much better than old Tesseract on book covers!

### Database errors
- Ensure PostgreSQL is running: `docker-compose ps`
- Run migrations: `alembic upgrade head`

### "VLM API timeout" or slow responses
- **Cause**: Network latency or API rate limits
- **Fix**: Wait a moment and try again
- **Cost**: ~$0.0001-0.0008 per scan (very cheap!)

## Documentation

- **[BOOK_SCANNER_README.md](BOOK_SCANNER_README.md)** - Complete architecture and documentation
- **[QUICK_START.md](QUICK_START.md)** - Step-by-step setup guide
- **[frontend/FRONTEND_TODO.md](frontend/FRONTEND_TODO.md)** - Frontend development guide
- **[deployment.md](deployment.md)** - Production deployment
- **[development.md](development.md)** - Local development setup

## License

MIT License - See [LICENSE](LICENSE) file for details.

## Acknowledgments

Built with the [FastAPI Full Stack Template](https://github.com/fastapi/full-stack-fastapi-template)
